{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c640bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries for data analysis and visualisation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038c2f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3faa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=('C:\\\\Users\\\\Windows\\\\Desktop\\\\Aston_msc_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(file_path)#file directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()#view of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2a774",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary = {\n",
    "    'Shape': data.shape,\n",
    "    'Columns':data.columns.tolist(),\n",
    "    'Descriptive Statistics':data.describe(include='all', datetime_is_numeric=True) #data summary\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1750587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Categorize data based on 'Ethnicity'\n",
    "ethnicity_conditions = [\n",
    "    data['Ethnicity'].str.contains('Pakistani', na=False),\n",
    "    data['Ethnicity'].str.contains('Indian', na=False),\n",
    "    (data['Ethnicity'].str.contains('Asian', na=False) & ~data['Ethnicity'].str.contains('Pakistani|Indian', na=False)),\n",
    "    data['Ethnicity'].str.contains('Black', na=False),\n",
    "    data['Ethnicity'].str.contains('White', na=False)\n",
    "]\n",
    "ethnicity_choices = ['Asian Pakistani', 'Asian Indian', 'Asian Other', 'Black', 'White']\n",
    "data['Ethnicity Category'] = pd.np.select(ethnicity_conditions, ethnicity_choices, default='Other')\n",
    "\n",
    "# Categorize data based on 'Highest Qualification'\n",
    "qualification_conditions = [\n",
    "    data['Highest Qualification'].str.contains('A/AS level', na=False),\n",
    "    data['Highest Qualification'].str.contains('BTEC', na=False),\n",
    "    (data['Highest Qualification'].str.contains('level 3', na=False) & ~data['Highest Qualification'].str.contains('A/AS level|BTEC', na=False))\n",
    "]\n",
    "qualification_choices = ['A-Level', 'L3 Diploma (BTEC)', 'Other L3']\n",
    "data['Qualification Category'] = pd.np.select(qualification_conditions, qualification_choices, default='Other')\n",
    "\n",
    "# Create a pivot table to summarize the counts of students in each category\n",
    "summary_table = data.pivot_table(index='Ethnicity Category', columns='Qualification Category', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Print the summary table\n",
    "print(summary_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef78c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the total number of students per ethnic category\n",
    "total_counts = summary_table.sum(axis=1)\n",
    "\n",
    "# Convert the counts to percentages\n",
    "percentage_table = summary_table.divide(total_counts, axis=0) * 100\n",
    "\n",
    "# Plot a stacked bar chart with custom colors using percentages\n",
    "custom_colors = ['#800000', '#1f77b4', '#2ca02c', '#ff7f0e']  # Maroon for A-Level, others for BTEC, Other, Other L3\n",
    "\n",
    "# Plot the percentage-based stacked bar chart\n",
    "ax = percentage_table.plot(kind='bar', stacked=True, figsize=(10, 6), color=custom_colors)\n",
    "\n",
    "# Add percentage labels on each bar\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.text(x + width/2, y + height/2, f'{height:.0f}%', ha='center', va='center', color='white', fontsize=10)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Percentage Distribution of Students by Ethnicity and Qualification Category', fontsize=16)\n",
    "plt.xlabel('Ethnicity Category', fontsize=12)\n",
    "plt.ylabel('Percentage of Students (%)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title='Qualification Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4e0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values in the 'Ethnicity' column to guide mapping\n",
    "unique_ethnicities = data['Ethnicity'].unique()\n",
    "unique_ethnicities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e247cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Ethnicity to broader categories\n",
    "ethnicity_mapping = {\n",
    "    'Asian or Asian British - Bangladeshi': 'Asian Other',\n",
    "    'Asian or Asian British - Pakistani': 'Asian Pakistani',\n",
    "    'White - British': 'White',\n",
    "    'White': 'White',\n",
    "    'Black or Black British - African': 'Black',\n",
    "    'Mixed - White & Asian': 'Asian Other',\n",
    "    'Asian Other': 'Asian Other',\n",
    "    'Asian or Asian British - Indian': 'Asian Indian',\n",
    "    'Other Black Background': 'Black',\n",
    "    'Other Mixed Background': 'Other',\n",
    "    'Mixed - White & Black African': 'Black',\n",
    "    'Chinese': 'Asian Other',\n",
    "    'Other Ethnic Background': 'Other',\n",
    "    'Black or Black British - Caribbean': 'Black',\n",
    "    'Arab': 'Other',\n",
    "    'Prefer not to say': 'Other',\n",
    "    'Mixed - White & Black Caribbean': 'Black',\n",
    "    'Not Known (UCAS code)': 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "data['Ethnicity Category'] = data['Ethnicity'].map(ethnicity_mapping)\n",
    "\n",
    "# Check the counts for each ethnicity category\n",
    "ethnicity_counts = data['Ethnicity Category'].value_counts()\n",
    "ethnicity_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Highest Qualification to specified categories\n",
    "qualification_mapping = {\n",
    "    'Diploma at level 3': 'L3 diploma (BTEC)',\n",
    "    'A/AS level': 'A-level',\n",
    "    'BTEC National Diploma/Certificate': 'L3 diploma (BTEC)',\n",
    "    'Level 3 quals (all are in UCAS tariff)': 'Other L3',\n",
    "    'Other qualification at level 2': 'Other',\n",
    "    'Level 3 quals (none are in UCAS Tariff)': 'Other L3',\n",
    "    'Other qualification level not known': 'Other',\n",
    "    'Level 3 quals (some are in UCAS tariff)': 'Other L3',\n",
    "    'International Baccalaureate (IB) Diploma': 'Other L3',\n",
    "    'HE access course, QAA recognised': 'Other L3',\n",
    "    'Higher Apprenticeship (level 4)': 'Other',\n",
    "    'Higher National Diploma (HND)': 'Other',\n",
    "    'Certificate of Higher Education (CertHE)': 'Other',\n",
    "    'UK first degree with honours': 'Other',\n",
    "    'Higher National Certificate (HNC)': 'Other',\n",
    "    'Other qualification at level C': 'Other',\n",
    "    'Certificate at level 3': 'L3 diploma (BTEC)',\n",
    "    'EU Level 3 eg. Maturia/Matura, Diplomasi, Abitur': 'Other L3',\n",
    "    0: 'Other',\n",
    "    'Mature stu admitted on prev exp / admissions test': 'Other',\n",
    "    'International Baccalaureate (IB) Certificate': 'A-level',\n",
    "    'Foundation degree': 'Other',\n",
    "    'Foundation course at level J': 'Other',\n",
    "    'Other qualification at level 3': 'Other L3',\n",
    "    'Not known': 'Other',\n",
    "    'Non EU Level 3 eg. High School Cert/Dip,  XII,': 'Other L3',\n",
    "    'EU (non-UK) first degree': 'Other',\n",
    "    'Diploma of Higher Education (DipHE)': 'Other',\n",
    "    'Non-EU masters degree': 'Other'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "data['Qualification Category'] = data['Highest Qualification'].map(qualification_mapping)\n",
    "\n",
    "# Check the counts for each qualification category\n",
    "qualification_counts = data['Qualification Category'].value_counts()\n",
    "qualification_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106cd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cross-tabulation of Ethnicity Category and Qualification Category\n",
    "tabulation = pd.crosstab(data['Ethnicity Category'], data['Qualification Category'])\n",
    "\n",
    "# Display the cross-tabulation\n",
    "tabulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d802225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unique values in the 'Disability?' column to guide the mapping\n",
    "unique_disabilities = data['Disability?'].unique()\n",
    "unique_disabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the disability mapping based on the provided categories\n",
    "disability_mapping = {\n",
    "    'No disability': 'No disability',\n",
    "    'Learning difficulty such as Dyslexia, Dyspraxia or AD(H)D': 'Neurodiversity',\n",
    "    'Two or more impairments &/or disabling medical condition': 'Other',\n",
    "    'Mental health condition challenge or disorder such as depression, schizophrenia or anxiety': 'Neurodiversity',\n",
    "    0: 'Other',\n",
    "    'Deaf or have a hearing impairment': 'Physical',\n",
    "    'Long term illness or health condition such as cancer, diabetes, chronic heart disease, HIV or epilepsy': 'Physical',\n",
    "    'Disability, impairment or medical issue not listed': 'Other',\n",
    "    'Not known': 'Other',\n",
    "    \"A social/communication impairment such as Asperger's syndrome/other autistic spectrum disorder\": 'Neurodiversity',\n",
    "    'Social or communication condition such as aspergers or autism': 'Neurodiversity',\n",
    "    'Physical impairment, mobility or dexterity issue which might require you to use crutches': 'Physical',\n",
    "    'A disability, impairment or medical condition that is not listed above': 'Other',\n",
    "    'Blind or have a visual impairment uncorrected by glasses': 'Physical'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "data['Disability Category'] = data['Disability?'].map(disability_mapping).fillna('Other')\n",
    "\n",
    "# Check the counts for each disability category\n",
    "disability_counts = data['Disability Category'].value_counts()\n",
    "disability_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ac5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values across all columns in the dataset\n",
    "missing_values = data.isnull().sum()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a40f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b88307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the specified columns from the dataset and create a new DataFrame called 'fdata'\n",
    "fdata = data.drop(columns=['PAL Attendance', 'Socio Economic Classification', 'Final Module Score'])\n",
    "\n",
    "# Display the first few rows of the new DataFrame to confirm the columns have been removed\n",
    "fdata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in the 'Diagnostic Score' column\n",
    "diagnostic_missing = data['Diagnostic Score'].isnull().sum()\n",
    "diagnostic_missing, data['Diagnostic Score'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9635a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the data into two sets based on the module codes for GCSE and A-Level diagnostics\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "# Filtering the data for GCSE and A-Level diagnostics\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Displaying the number of entries in each set\n",
    "gcse_count = gcse_data.shape[0]\n",
    "a_level_count = a_level_data.shape[0]\n",
    "\n",
    "gcse_count, a_level_count, gcse_data.head(), a_level_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data\n",
    "missing_values_relevant = fdata[['Ethnicity', 'Age on Entry', 'Gender', 'Highest Qualification', 'Disability?']].isnull().sum()\n",
    "\n",
    "# Encode categorical data: Ethnicity, Gender, Highest Qualification, Disability\n",
    "fdata_encoded = pd.get_dummies(fdata, columns=['Ethnicity', 'Gender', 'Highest Qualification', 'Disability?'])\n",
    "\n",
    "# Display missing values in relevant features and a sample of the encoded DataFrame\n",
    "missing_values_relevant, fdata_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3aa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the data into two sets based on the module codes for GCSE and A-Level diagnostics\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "# Filtering the data for GCSE and A-Level diagnostics\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Displaying the number of entries in each set\n",
    "gcse_count = gcse_data.shape[0]\n",
    "a_level_count = a_level_data.shape[0]\n",
    "\n",
    "gcse_count, a_level_count, gcse_data.head(), a_level_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72088e85",
   "metadata": {},
   "source": [
    "# Application of UCAS Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50db3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCAS points conversion dictionary\n",
    "ucas_points = {\n",
    "    'A*': 56,\n",
    "    'A': 48,\n",
    "    'B': 40,\n",
    "    'C': 32,\n",
    "    'D': 24,\n",
    "    'E': 16\n",
    "}\n",
    "\n",
    "# Apply UCAS points conversion to the 'Grade' column where applicable, using 0 for others\n",
    "fdata['A-Level Score'] = fdata['Grade'].map(ucas_points).fillna(0)\n",
    "\n",
    "# Scores considered for A-Level module codes\n",
    "fdata['A-Level Score'] = fdata.apply(lambda x: x['A-Level Score'] if x['Module Code'] in a_level_modules else 0, axis=1)\n",
    "\n",
    "# Display a sample of the data to verify the integration\n",
    "print(fdata[['Module Code', 'Grade', 'A-Level Score']].sample(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158916fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the selected features for both datasets\n",
    "missing_values_gcse = gcse_data[['Ethnicity', 'Gender', 'Disability?', 'Age on Entry', 'Highest Qualification']].isnull().sum()\n",
    "missing_values_a_level = a_level_data[['Ethnicity', 'Gender', 'Disability?', 'Age on Entry', 'Highest Qualification']].isnull().sum()\n",
    "\n",
    "missing_values_gcse, missing_values_a_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fbcce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking for missing values in the other vital features\n",
    "missing_values_relevant = fdata[['Ethnicity', 'Age on Entry', 'Gender', 'Highest Qualification', 'Disability?']].isnull().sum()\n",
    "\n",
    "# Encode categorical data: Ethnicity, Gender, Highest Qualification, Disability\n",
    "fdata_encoded = pd.get_dummies(fdata, columns=['Ethnicity', 'Gender', 'Highest Qualification', 'Disability?'])\n",
    "\n",
    "# Display missing values in relevant features and a sample of the encoded DataFrame\n",
    "missing_values_relevant, fdata_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffd2ba",
   "metadata": {},
   "source": [
    "#  Selection Of The Features For Diagnostics Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20528bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select relevant features for the model, including 'A-Level Score', and categorical variables\n",
    "features = ['Age on Entry', 'A-Level Score'] + \\\n",
    "    [col for col in fdata_encoded.columns if 'Ethnicity_' in col or 'Gender_' in col or 'Disability_' in col or 'Highest Qualification_' in col]\n",
    "\n",
    "# Separate the data into those with known and unknown diagnostic scores\n",
    "known_scores = fdata_encoded.dropna(subset=['Diagnostic Score'])\n",
    "unknown_scores = fdata_encoded[fdata_encoded['Diagnostic Score'].isnull()]\n",
    "\n",
    "# Include only selected features for X (features) and y (target)\n",
    "X_known = known_scores[features]  # Independent variables for known diagnostic scores\n",
    "y_known = known_scores['Diagnostic Score']  # Dependent variable (target)\n",
    "X_unknown = unknown_scores[features]  # Independent variables for unknown diagnostic scores\n",
    "\n",
    "# Display the shape of the datasets to ensure correctness\n",
    "X_known.shape, y_known.shape, X_unknown.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48a008",
   "metadata": {},
   "source": [
    "# Integration Of The Scores Back Into Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65219571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrating 'A-Level Score' back into the known and unknown scores dataframes\n",
    "known_scores['A-Level Score'] = fdata.loc[known_scores.index, 'A-Level Score']\n",
    "unknown_scores['A-Level Score'] = fdata.loc[unknown_scores.index, 'A-Level Score']\n",
    "\n",
    "# Include only selected features again with the corrected datasets\n",
    "X_known = known_scores[features]\n",
    "y_known = known_scores['Diagnostic Score']\n",
    "X_unknown = unknown_scores[features]\n",
    "\n",
    "# Display the shape of the datasets to ensure correctness\n",
    "X_known.shape, y_known.shape, X_unknown.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41969894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66565a51",
   "metadata": {},
   "source": [
    "# Checking Suitable Model For The Diagonistics Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ca20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Initialize an imputer for numerical column employing median as the strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Fit the imputer and transform the training data\n",
    "X_known_imputed = imputer.fit_transform(X_known)\n",
    "X_unknown_imputed = imputer.transform(X_unknown)\n",
    "\n",
    "# Initialize the models\n",
    "gradient_boosting = GradientBoostingRegressor(random_state=42)\n",
    "linear_regression = LinearRegression()\n",
    "random_forest = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Gradient Boosting Regressor\n",
    "gradient_boosting.fit(X_known_imputed, y_known)\n",
    "gb_predictions = gradient_boosting.predict(X_known_imputed)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_known, gb_predictions))\n",
    "gb_r2 = r2_score(y_known, gb_predictions)\n",
    "\n",
    "# Train the Linear Regression\n",
    "linear_regression.fit(X_known_imputed, y_known)\n",
    "lr_predictions = linear_regression.predict(X_known_imputed)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_known, lr_predictions))\n",
    "lr_r2 = r2_score(y_known, lr_predictions)\n",
    "\n",
    "# Perform cross-validation for Random Forest Regressor\n",
    "cv_scores = cross_val_score(random_forest, X_known_imputed, y_known, cv=5, scoring='neg_mean_squared_error')\n",
    "# Train the Random Forest Regressor on the fully imputed known data\n",
    "random_forest.fit(X_known_imputed, y_known)\n",
    "rf_predictions = random_forest.predict(X_known_imputed)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_known, rf_predictions))\n",
    "rf_r2 = r2_score(y_known, rf_predictions)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Gradient Boosting RMSE: {gb_rmse}, R²: {gb_r2}\")\n",
    "print(f\"Linear Regression RMSE: {lr_rmse}, R²: {lr_r2}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse}, R²: {rf_r2}\")\n",
    "\n",
    "# Calculate the mean RMSE from cross-validation for Random Forest\n",
    "mse_scores = -cv_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "mean_rmse_cv = np.mean(rmse_scores)\n",
    "\n",
    "print(f\"Random Forest Cross-Validation Mean RMSE: {mean_rmse_cv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff52e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058c9c1f",
   "metadata": {},
   "source": [
    "# Utilizing The Best Model (Random Forest Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62016de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the missing diagnostic scores using the trained model\n",
    "predicted_scores = random_forest.predict(X_unknown_imputed)\n",
    "\n",
    "# Integrate these predictions back into the original dataset\n",
    "fdata.loc[unknown_scores.index, 'Diagnostic Score'] = predicted_scores\n",
    "\n",
    "# Show a sample of the data with the newly imputed diagnostic scores\n",
    "fdata.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the counts of non-missing and imputed diagnostic scores\n",
    "diagnostic_counts = fdata['Diagnostic Score'].isnull().value_counts()\n",
    "print(diagnostic_counts)\n",
    "\n",
    "# Show a sample of the data with the newly imputed diagnostic scores\n",
    "fdata[['Module Code', 'Diagnostic Score', 'A-Level Score']].sample(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec53f30",
   "metadata": {},
   "source": [
    "# Import Libraries and Define Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651fc600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for statistical tests and plotting\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the module codes for GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8e66f",
   "metadata": {},
   "source": [
    "# Split Data into GCSE and A-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into GCSE and A-Level datasets\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Extract diagnostic scores for GCSE and A-Level modules\n",
    "gcse_diagnostic_scores = gcse_data['Diagnostic Score']\n",
    "a_level_diagnostic_scores = a_level_data['Diagnostic Score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781138ec",
   "metadata": {},
   "source": [
    "# Plot Histograms and Q-Q Plots for GCSE Diagnostic Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de59f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and Q-Q plots for GCSE diagnostic scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(gcse_diagnostic_scores, kde=True)\n",
    "plt.title('Histogram of GCSE Diagnostic Scores')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(gcse_diagnostic_scores, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of GCSE Diagnostic Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5444d0",
   "metadata": {},
   "source": [
    "# Plot Histograms and Q-Q Plots for A-Level Diagnostic Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9626c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and Q-Q plots for A-Level diagnostic scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(a_level_diagnostic_scores, kde=True)\n",
    "plt.title('Histogram of A-Level Diagnostic Scores')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(a_level_diagnostic_scores, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of A-Level Diagnostic Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d717e",
   "metadata": {},
   "source": [
    "# Perform Shapiro-Wilk and Kolmogorov-Smirnov Tests for GCSE Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Shapiro-Wilk test for GCSE diagnostic scores\n",
    "shapiro_gcse = stats.shapiro(gcse_diagnostic_scores)\n",
    "print(f'Shapiro-Wilk Test for GCSE Diagnostic Scores: Statistic={shapiro_gcse[0]}, p-value={shapiro_gcse[1]}')\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test for GCSE diagnostic scores\n",
    "ks_gcse = stats.kstest(gcse_diagnostic_scores, 'norm', args=(gcse_diagnostic_scores.mean(), gcse_diagnostic_scores.std()))\n",
    "print(f'Kolmogorov-Smirnov Test for GCSE Diagnostic Scores: Statistic={ks_gcse[0]}, p-value={ks_gcse[1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e737ae9",
   "metadata": {},
   "source": [
    "# Perform Shapiro-Wilk and Kolmogorov-Smirnov Tests for A-Level Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b057ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Shapiro-Wilk test for A-Level diagnostic scores\n",
    "shapiro_a_level = stats.shapiro(a_level_diagnostic_scores)\n",
    "print(f'Shapiro-Wilk Test for A-Level Diagnostic Scores: Statistic={shapiro_a_level[0]}, p-value={shapiro_a_level[1]}')\n",
    "\n",
    "# Perform Kolmogorov-Smirnov test for A-Level diagnostic scores\n",
    "ks_a_level = stats.kstest(a_level_diagnostic_scores, 'norm', args=(a_level_diagnostic_scores.mean(), a_level_diagnostic_scores.std()))\n",
    "print(f'Kolmogorov-Smirnov Test for A-Level Diagnostic Scores: Statistic={ks_a_level[0]}, p-value={ks_a_level[1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef199b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the summary statistics function\n",
    "def summary_statistics(group):\n",
    "    return {\n",
    "        'Mean': group.mean(),\n",
    "        'Median': group.median(),\n",
    "        'Std Dev': group.std(),\n",
    "        'Count': group.count()\n",
    "    }\n",
    "\n",
    "# Ethnicity groups\n",
    "ethnicity_groups = ['Black', 'Asian Pakistani', 'White', 'Asian Other', 'Asian Indian', 'Other']\n",
    "\n",
    "# Calculate summary statistics for GCSE data\n",
    "gcse_summary_stats = {ethnicity: summary_statistics(gcse_data[gcse_data['Ethnicity Category'] == ethnicity]['Diagnostic Score']) for ethnicity in ethnicity_groups}\n",
    "\n",
    "# Calculate summary statistics for A-level data\n",
    "a_level_summary_stats = {ethnicity: summary_statistics(a_level_data[a_level_data['Ethnicity Category'] == ethnicity]['Diagnostic Score']) for ethnicity in ethnicity_groups}\n",
    "\n",
    "# Convert the summary statistics dictionaries to DataFrames\n",
    "gcse_summary_table = pd.DataFrame(gcse_summary_stats).T\n",
    "a_level_summary_table = pd.DataFrame(a_level_summary_stats).T\n",
    "\n",
    "# Display the summary statistics tables\n",
    "gcse_summary_table, a_level_summary_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e11856",
   "metadata": {},
   "source": [
    "# Kruskal-Wallis test for GCSE & A-Level(Ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524ff64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal-Wallis test for GCSE data\n",
    "gcse_grouped = [gcse_data[gcse_data['Ethnicity Category'] == ethnicity]['Diagnostic Score'] for ethnicity in ethnicity_groups]\n",
    "gcse_kruskal_test = kruskal(*gcse_grouped)\n",
    "\n",
    "# Kruskal-Wallis test for A-level data\n",
    "a_level_grouped = [a_level_data[a_level_data['Ethnicity Category'] == ethnicity]['Diagnostic Score'] for ethnicity in ethnicity_groups]\n",
    "a_level_kruskal_test = kruskal(*a_level_grouped)\n",
    "\n",
    "gcse_kruskal_test, a_level_kruskal_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f16e222",
   "metadata": {},
   "source": [
    "# Summary of Kruskal-Wallis test for GCSE & A-Level(Ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print GCSE summary statistics\n",
    "print(\"GCSE Summary Statistics by Ethnic Group\")\n",
    "print(gcse_summary_table)\n",
    "\n",
    "# Print A-level summary statistics\n",
    "print(\"A-Level Summary Statistics by Ethnic Group\")\n",
    "print(a_level_summary_table)\n",
    "\n",
    "# Print Kruskal-Wallis test results\n",
    "print(f\"Kruskal-Wallis Test for GCSE Diagnostic Scores: H-statistic={gcse_kruskal_test.statistic}, p-value={gcse_kruskal_test.pvalue}\")\n",
    "print(f\"Kruskal-Wallis Test for A-Level Diagnostic Scores: H-statistic={a_level_kruskal_test.statistic}, p-value={a_level_kruskal_test.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f1aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c04ee32c",
   "metadata": {},
   "source": [
    "# Applying the Mapping to the GCSE and A-Level Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data['Qualification Category'] = gcse_data['Highest Qualification'].map(qualification_mapping)\n",
    "a_level_data['Qualification Category'] = a_level_data['Highest Qualification'].map(qualification_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d5709",
   "metadata": {},
   "source": [
    "# Grouping the Data by Qualification Category for GCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_qualification_groups = gcse_data['Qualification Category'].unique()\n",
    "gcse_grouped_by_qualification = [gcse_data[gcse_data['Qualification Category'] == qual]['Diagnostic Score'] for qual in gcse_qualification_groups]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f240bf9b",
   "metadata": {},
   "source": [
    "# Performing the Kruskal-Wallis Test for GCSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_kruskal_qualification_test = kruskal(*gcse_grouped_by_qualification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5564b7b",
   "metadata": {},
   "source": [
    "# Grouping the Data by Qualification Category for A-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf7ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_qualification_groups = a_level_data['Qualification Category'].unique()\n",
    "a_level_grouped_by_qualification = [a_level_data[a_level_data['Qualification Category'] == qual]['Diagnostic Score'] for qual in a_level_qualification_groups]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e36b3",
   "metadata": {},
   "source": [
    "# Performing the Kruskal-Wallis Test for A-Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdda912",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_kruskal_qualification_test = kruskal(*a_level_grouped_by_qualification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19325a80",
   "metadata": {},
   "source": [
    "# KW Test Results for Qualification category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Kruskal-Wallis Test for GCSE Diagnostic Scores by Previous Qualification: H-statistic={gcse_kruskal_qualification_test.statistic}, p-value={gcse_kruskal_qualification_test.pvalue}\")\n",
    "print(f\"Kruskal-Wallis Test for A-Level Diagnostic Scores by Previous Qualification: H-statistic={a_level_kruskal_qualification_test.statistic}, p-value={a_level_kruskal_qualification_test.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ffae94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd927ee0",
   "metadata": {},
   "source": [
    "# Grouping based on Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data based on 'Age on Entry' into Young and Mature categories\n",
    "age_threshold = 21\n",
    "gcse_data['Age Category'] = np.where(gcse_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "a_level_data['Age Category'] = np.where(a_level_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "\n",
    "# Display the counts for each age category in both datasets\n",
    "gcse_age_counts = gcse_data['Age Category'].value_counts()\n",
    "a_level_age_counts = a_level_data['Age Category'].value_counts()\n",
    "\n",
    "print(\"GCSE Age Category Counts:\\n\", gcse_age_counts)\n",
    "print(\"\\nA-Level Age Category Counts:\\n\", a_level_age_counts)\n",
    "\n",
    "# Display a sample of the data to verify the new column\n",
    "gcse_data[['Age on Entry', 'Age Category']].sample(10)\n",
    "a_level_data[['Age on Entry', 'Age Category']].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cae14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "818a0cb5",
   "metadata": {},
   "source": [
    "# KW test for the Age Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4abd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtering the data for GCSE and A-Level diagnostics\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Group data based on 'Age on Entry' into Young and Mature categories\n",
    "age_threshold = 21\n",
    "gcse_data['Age Category'] = np.where(gcse_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "a_level_data['Age Category'] = np.where(a_level_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "\n",
    "# Separate the diagnostic scores based on the 'Age Category'\n",
    "gcse_young_scores = gcse_data[gcse_data['Age Category'] == 'Mature']['Diagnostic Score']\n",
    "gcse_mature_scores = gcse_data[gcse_data['Age Category'] == 'Young']['Diagnostic Score']\n",
    "\n",
    "a_level_young_scores = a_level_data[a_level_data['Age Category'] == 'Mature']['Diagnostic Score']\n",
    "a_level_mature_scores = a_level_data[a_level_data['Age Category'] == 'Young']['Diagnostic Score']\n",
    "\n",
    "# Perform the Kruskal-Wallis test on the diagnostic scores\n",
    "gcse_kw_result = kruskal(gcse_mature_scores, gcse_young_scores)\n",
    "a_level_kw_result = kruskal(a_level_mature_scores, a_level_young_scores)\n",
    "\n",
    "print(\"GCSE Kruskal-Wallis Test Result:\\n\", gcse_kw_result)\n",
    "print(\"\\nA-Level Kruskal-Wallis Test Result:\\n\", a_level_kw_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5cbe82",
   "metadata": {},
   "source": [
    "# KW test for the Disability Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the disability mapping based on the provided categories\n",
    "disability_mapping = {\n",
    "    'No disability': 'No disability',\n",
    "    'Learning difficulty such as Dyslexia, Dyspraxia or AD(H)D': 'Neurodiversity',\n",
    "    'Two or more impairments &/or disabling medical condition': 'Other',\n",
    "    'Mental health condition challenge or disorder such as depression, schizophrenia or anxiety': 'Neurodiversity',\n",
    "    0: 'Other',\n",
    "    'Deaf or have a hearing impairment': 'Physical',\n",
    "    'Long term illness or health condition such as cancer, diabetes, chronic heart disease, HIV or epilepsy': 'Physical',\n",
    "    'Disability, impairment or medical issue not listed': 'Other',\n",
    "    'Not known': 'Other',\n",
    "    \"A social/communication impairment such as Asperger's syndrome/other autistic spectrum disorder\": 'Neurodiversity',\n",
    "    'Social or communication condition such as aspergers or autism': 'Neurodiversity',\n",
    "    'Physical impairment, mobility or dexterity issue which might require you to use crutches': 'Physical',\n",
    "    'A disability, impairment or medical condition that is not listed above': 'Other',\n",
    "    'Blind or have a visual impairment uncorrected by glasses': 'Physical'\n",
    "}\n",
    "\n",
    "# Apply the mapping to the dataset\n",
    "fdata['Disability Category'] = fdata['Disability?'].map(disability_mapping).fillna('Other')\n",
    "\n",
    "# Check the counts for each disability category\n",
    "disability_counts = fdata['Disability Category'].value_counts()\n",
    "print(\"Counts of each disability category:\")\n",
    "print(disability_counts)\n",
    "\n",
    "# Define the module codes for GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "# Split the data into GCSE and A-Level datasets\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Perform the Kruskal-Wallis test for GCSE diagnostic scores\n",
    "gcse_grouped = [gcse_data[gcse_data['Disability Category'] == category]['Diagnostic Score'].dropna() for category in gcse_data['Disability Category'].unique()]\n",
    "gcse_kruskal_test = kruskal(*gcse_grouped)\n",
    "\n",
    "# Perform the Kruskal-Wallis test for A-level diagnostic scores\n",
    "a_level_grouped = [a_level_data[a_level_data['Disability Category'] == category]['Diagnostic Score'].dropna() for category in a_level_data['Disability Category'].unique()]\n",
    "a_level_kruskal_test = kruskal(*a_level_grouped)\n",
    "\n",
    "print(\"Kruskal-Wallis test results for GCSE diagnostic scores:\", gcse_kruskal_test)\n",
    "print(\"Kruskal-Wallis test results for A-level diagnostic scores:\", a_level_kruskal_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b494fcb",
   "metadata": {},
   "source": [
    "# Visual Observation(Disability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe7e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot for GCSE diagnostic scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=gcse_data, x='Disability Category', y='Diagnostic Score')\n",
    "plt.title('GCSE Diagnostic Scores by Disability Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Disability Category')\n",
    "plt.ylabel('Diagnostic Score')\n",
    "plt.show()\n",
    "\n",
    "# Plot for A-Level diagnostic scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=a_level_data, x='Disability Category', y='Diagnostic Score')\n",
    "plt.title('A-Level Diagnostic Scores by Disability Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Disability Category')\n",
    "plt.ylabel('Diagnostic Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb47f9",
   "metadata": {},
   "source": [
    "# KW test for Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaffc7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "\n",
    "# Group the data by gender for GCSE and A-Level separately\n",
    "gcse_grouped_by_gender = gcse_data.groupby('Gender')\n",
    "a_level_grouped_by_gender = a_level_data.groupby('Gender')\n",
    "\n",
    "# Extract the diagnostic scores for each gender group in GCSE\n",
    "gcse_male_scores = gcse_grouped_by_gender.get_group('M')['Diagnostic Score']\n",
    "gcse_female_scores = gcse_grouped_by_gender.get_group('F')['Diagnostic Score']\n",
    "\n",
    "# Perform the Kruskal-Wallis test for GCSE diagnostic scores by gender\n",
    "gcse_kruskal_gender_test = stats.kruskal(gcse_male_scores, gcse_female_scores)\n",
    "\n",
    "print(f\"Kruskal-Wallis Test for GCSE Diagnostic Scores by Gender: H-statistic={gcse_kruskal_gender_test.statistic}, p-value={gcse_kruskal_gender_test.pvalue}\")\n",
    "\n",
    "# Extract the diagnostic scores for each gender group in A-Level\n",
    "a_level_male_scores = a_level_grouped_by_gender.get_group('M')['Diagnostic Score']\n",
    "a_level_female_scores = a_level_grouped_by_gender.get_group('F')['Diagnostic Score']\n",
    "\n",
    "# Perform the Kruskal-Wallis test for A-Level diagnostic scores by gender\n",
    "a_level_kruskal_gender_test = stats.kruskal(a_level_male_scores, a_level_female_scores)\n",
    "\n",
    "print(f\"Kruskal-Wallis Test for A-Level Diagnostic Scores by Gender: H-statistic={a_level_kruskal_gender_test.statistic}, p-value={a_level_kruskal_gender_test.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c256c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0efb8fe2",
   "metadata": {},
   "source": [
    "# Dunn's test for Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikit_posthocs import posthoc_dunn\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for GCSE gender groups\n",
    "gcse_gender_data = pd.DataFrame({\n",
    "    'Score': pd.concat([gcse_male_scores, gcse_female_scores]),\n",
    "    'Gender': ['Male'] * len(gcse_male_scores) + ['Female'] * len(gcse_female_scores)\n",
    "})\n",
    "\n",
    "# Perform Dunn's test for GCSE gender groups\n",
    "gcse_dunn_test_gender = posthoc_dunn(gcse_gender_data, val_col='Score', group_col='Gender', p_adjust='bonferroni')\n",
    "print(\"Dunn's post-hoc test for GCSE Diagnostic Scores by Gender:\")\n",
    "print(gcse_dunn_test_gender)\n",
    "\n",
    "# Create a DataFrame for A-Level gender groups\n",
    "a_level_gender_data = pd.DataFrame({\n",
    "    'Score': pd.concat([a_level_male_scores, a_level_female_scores]),\n",
    "    'Gender': ['Male'] * len(a_level_male_scores) + ['Female'] * len(a_level_female_scores)\n",
    "})\n",
    "\n",
    "# Perform Dunn's test for A-Level gender groups\n",
    "a_level_dunn_test_gender = posthoc_dunn(a_level_gender_data, val_col='Score', group_col='Gender', p_adjust='bonferroni')\n",
    "print(\"Dunn's post-hoc test for A-Level Diagnostic Scores by Gender:\")\n",
    "print(a_level_dunn_test_gender)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ec56ee",
   "metadata": {},
   "source": [
    "# Calculation of mean and median for Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Create a DataFrame for GCSE gender groups\n",
    "gcse_gender_data = pd.DataFrame({\n",
    "    'Score': pd.concat([gcse_male_scores, gcse_female_scores]),\n",
    "    'Gender': ['Male'] * len(gcse_male_scores) + ['Female'] * len(gcse_female_scores)\n",
    "})\n",
    "\n",
    "# Calculate mean, median, standard deviation, and count for GCSE scores by gender\n",
    "gcse_summary = gcse_gender_data.groupby('Gender')['Score'].agg(\n",
    "    Mean='mean',\n",
    "    Median='median',\n",
    "    Std_Dev='std',\n",
    "    Count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(\"GCSE Summary Statistics by Gender:\")\n",
    "print(gcse_summary)\n",
    "\n",
    "# Dunn's test for GCSE gender groups\n",
    "gcse_dunn_test_gender = posthoc_dunn(gcse_gender_data, val_col='Score', group_col='Gender', p_adjust='bonferroni')\n",
    "print(\"\\nDunn's post-hoc test for GCSE Diagnostic Scores by Gender:\")\n",
    "print(gcse_dunn_test_gender)\n",
    "\n",
    "# Creating DataFrame for A-Level gender groups\n",
    "a_level_gender_data = pd.DataFrame({\n",
    "    'Score': pd.concat([a_level_male_scores, a_level_female_scores]),\n",
    "    'Gender': ['Male'] * len(a_level_male_scores) + ['Female'] * len(a_level_female_scores)\n",
    "})\n",
    "\n",
    "# Calculatating mean, median, standard deviation, and count for A-Level scores by gender\n",
    "a_level_summary = a_level_gender_data.groupby('Gender')['Score'].agg(\n",
    "    Mean='mean',\n",
    "    Median='median',\n",
    "    Std_Dev='std',\n",
    "    Count='count'\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\nA-Level Summary Statistics by Gender:\")\n",
    "print(a_level_summary)\n",
    "\n",
    "# Perform Dunn's test for A-Level gender groups\n",
    "a_level_dunn_test_gender = posthoc_dunn(a_level_gender_data, val_col='Score', group_col='Gender', p_adjust='bonferroni')\n",
    "print(\"\\nDunn's post-hoc test for A-Level Diagnostic Scores by Gender:\")\n",
    "print(a_level_dunn_test_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512502b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "115c201f",
   "metadata": {},
   "source": [
    "# Dunn's test for Previous Qualification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360061f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for statistical tests and plotting\n",
    "from scipy import stats\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "#module codes for GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "#GCSE and A-Level datasets\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)].copy()\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)].copy()\n",
    "\n",
    "# Mapping the highest qualification to the new categories\n",
    "gcse_data.loc[:, 'Qualification Category'] = gcse_data['Highest Qualification'].map(qualification_mapping)\n",
    "a_level_data.loc[:, 'Qualification Category'] = a_level_data['Highest Qualification'].map(qualification_mapping)\n",
    "\n",
    "# Performing Kruskal-Wallis test for GCSE diagnostic scores by previous qualification\n",
    "gcse_qualification_groups = gcse_data['Qualification Category'].unique()\n",
    "gcse_grouped_by_qualification = [gcse_data[gcse_data['Qualification Category'] == qual]['Diagnostic Score'] for qual in gcse_qualification_groups]\n",
    "gcse_kruskal_qualification_test = stats.kruskal(*gcse_grouped_by_qualification)\n",
    "\n",
    "# Performing Kruskal-Wallis test for A-Level diagnostic scores by previous qualification\n",
    "a_level_qualification_groups = a_level_data['Qualification Category'].unique()\n",
    "a_level_grouped_by_qualification = [a_level_data[a_level_data['Qualification Category'] == qual]['Diagnostic Score'] for qual in a_level_qualification_groups]\n",
    "a_level_kruskal_qualification_test = stats.kruskal(*a_level_grouped_by_qualification)\n",
    "\n",
    "print(f\"Kruskal-Wallis Test for GCSE Diagnostic Scores by Previous Qualification: H-statistic={gcse_kruskal_qualification_test.statistic}, p-value={gcse_kruskal_qualification_test.pvalue}\")\n",
    "print(f\"Kruskal-Wallis Test for A-Level Diagnostic Scores by Previous Qualification: H-statistic={a_level_kruskal_qualification_test.statistic}, p-value={a_level_kruskal_qualification_test.pvalue}\")\n",
    "\n",
    "# Post Hoc analysis using Dunn's test for GCSE diagnostic scores by previous qualification\n",
    "gcse_dunn_test = sp.posthoc_dunn(gcse_data, val_col='Diagnostic Score', group_col='Qualification Category', p_adjust='bonferroni')\n",
    "print(\"Dunn's test results for GCSE diagnostic scores by previous qualification:\")\n",
    "print(gcse_dunn_test)\n",
    "\n",
    "# Post Hoc analysis using Dunn's test for A-Level diagnostic scores by previous qualification\n",
    "a_level_dunn_test = sp.posthoc_dunn(a_level_data, val_col='Diagnostic Score', group_col='Qualification Category', p_adjust='bonferroni')\n",
    "print(\"Dunn's test results for A-Level diagnostic scores by previous qualification:\")\n",
    "print(a_level_dunn_test)\n",
    "\n",
    "#Visualizing the results using boxplots\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=gcse_data, x='Qualification Category', y='Diagnostic Score')\n",
    "plt.title('GCSE Diagnostic Scores by Qualification Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=a_level_data, x='Qualification Category', y='Diagnostic Score')\n",
    "plt.title('A-Level Diagnostic Scores by Qualification Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac741236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b103820",
   "metadata": {},
   "source": [
    "The pairwise comparisons for A-Level diagnostic scores reveal the following significant differences:\n",
    "\n",
    "A-level vs. L3 diploma (BTEC): Significant difference (p < 0.05)\n",
    "A-level vs. Other: Significant difference (p < 0.05)\n",
    "A-level vs. Other L3: Significant difference (p < 0.05)\n",
    "L3 diploma (BTEC) vs. Other L3: Significant difference (p < 0.05)\n",
    "\n",
    "No significant differences were found between:\n",
    "L3 diploma (BTEC) vs. Other\n",
    "Other vs. Other L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3695815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b847de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9e6b5ca",
   "metadata": {},
   "source": [
    "# Calculation of mean and median of A-level scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7118b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median scores for each qualification category\n",
    "median_scores = a_level_data.groupby('Qualification Category')['Diagnostic Score'].median()\n",
    "print(\"Median Diagnostic Scores by Qualification Category:\")\n",
    "print(median_scores)\n",
    "\n",
    "# calculating mean scores for further insight\n",
    "mean_scores = a_level_data.groupby('Qualification Category')['Diagnostic Score'].mean()\n",
    "print(\"Mean Diagnostic Scores by Qualification Category:\")\n",
    "print(mean_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392140e3",
   "metadata": {},
   "source": [
    "# Calculation of mean and median of GCSE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# median scores for each GCSE qualification category\n",
    "gcse_median_scores = gcse_data.groupby('Qualification Category')['Diagnostic Score'].median()\n",
    "print(\"Median GCSE Diagnostic Scores by Qualification Category:\")\n",
    "print(gcse_median_scores)\n",
    "\n",
    "# mean scores for each GCSE qualification category\n",
    "gcse_mean_scores = gcse_data.groupby('Qualification Category')['Diagnostic Score'].mean()\n",
    "print(\"Mean GCSE Diagnostic Scores by Qualification Category:\")\n",
    "print(gcse_mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef940183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc658263",
   "metadata": {},
   "source": [
    "# Dunn's test for Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Define the summary statistics function\n",
    "def summary_statistics(group):\n",
    "    return {\n",
    "        'Mean': group.mean(),\n",
    "        'Median': group.median(),\n",
    "        'Std Dev': group.std(),\n",
    "        'Count': group.count()\n",
    "    }\n",
    "\n",
    "# dataframes with the required data\n",
    "ethnicity_groups = ['Black', 'Asian Pakistani', 'White', 'Asian Other', 'Asian Indian', 'Other']\n",
    "\n",
    "# summary statistics for GCSE data\n",
    "gcse_summary_stats = {ethnicity: summary_statistics(gcse_data[gcse_data['Ethnicity Category'] == ethnicity]['Diagnostic Score']) for ethnicity in ethnicity_groups}\n",
    "\n",
    "# summary statistics for A-level data\n",
    "a_level_summary_stats = {ethnicity: summary_statistics(a_level_data[a_level_data['Ethnicity Category'] == ethnicity]['Diagnostic Score']) for ethnicity in ethnicity_groups}\n",
    "\n",
    "# Converting the summary statistics dictionaries to DataFrames\n",
    "gcse_summary_table = pd.DataFrame(gcse_summary_stats).T\n",
    "a_level_summary_table = pd.DataFrame(a_level_summary_stats).T\n",
    "\n",
    "# Display the summary statistics tables\n",
    "print(\"GCSE Summary Statistics by Ethnic Group\")\n",
    "print(gcse_summary_table)\n",
    "\n",
    "print(\"\\nA-Level Summary Statistics by Ethnic Group\")\n",
    "print(a_level_summary_table)\n",
    "\n",
    "# Kruskal-Wallis test for GCSE data\n",
    "gcse_grouped = [gcse_data[gcse_data['Ethnicity Category'] == ethnicity]['Diagnostic Score'] for ethnicity in ethnicity_groups]\n",
    "gcse_kruskal_test = kruskal(*gcse_grouped)\n",
    "\n",
    "# Kruskal-Wallis test for A-level data\n",
    "a_level_grouped = [a_level_data[a_level_data['Ethnicity Category'] == ethnicity]['Diagnostic Score'] for ethnicity in ethnicity_groups]\n",
    "a_level_kruskal_test = kruskal(*a_level_grouped)\n",
    "\n",
    "print(f\"\\nKruskal-Wallis Test for GCSE Diagnostic Scores: H-statistic={gcse_kruskal_test.statistic}, p-value={gcse_kruskal_test.pvalue}\")\n",
    "print(f\"Kruskal-Wallis Test for A-Level Diagnostic Scores: H-statistic={a_level_kruskal_test.statistic}, p-value={a_level_kruskal_test.pvalue}\")\n",
    "\n",
    "# Dunn's test for GCSE and A-Level diagnostic scores\n",
    "gcse_dunn_test = posthoc_dunn(gcse_data, val_col='Diagnostic Score', group_col='Ethnicity Category', p_adjust='bonferroni')\n",
    "a_level_dunn_test = posthoc_dunn(a_level_data, val_col='Diagnostic Score', group_col='Ethnicity Category', p_adjust='bonferroni')\n",
    "\n",
    "# Tabulate Dunn's test results\n",
    "print(\"\\nDunn's test results for GCSE diagnostic scores by ethnicity:\")\n",
    "print(gcse_dunn_test)\n",
    "\n",
    "print(\"\\nDunn's test results for A-Level diagnostic scores by ethnicity:\")\n",
    "print(a_level_dunn_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67a8694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021bf13e",
   "metadata": {},
   "source": [
    "# Dunn's Test for the Age Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fe9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "\n",
    "# Filtering the data for GCSE and A-Level diagnostics\n",
    "gcse_data = fdata[fdata['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata[fdata['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Group data based on 'Age on Entry' into Young and Mature categories\n",
    "age_threshold = 21\n",
    "gcse_data['Age Category'] = np.where(gcse_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "a_level_data['Age Category'] = np.where(a_level_data['Age on Entry'] >= age_threshold, 'Mature', 'Young')\n",
    "\n",
    "# Separate the diagnostic scores based on the 'Age Category'\n",
    "gcse_young_scores = gcse_data[gcse_data['Age Category'] == 'Young']['Diagnostic Score']\n",
    "gcse_mature_scores = gcse_data[gcse_data['Age Category'] == 'Mature']['Diagnostic Score']\n",
    "\n",
    "a_level_young_scores = a_level_data[a_level_data['Age Category'] == 'Young']['Diagnostic Score']\n",
    "a_level_mature_scores = a_level_data[a_level_data['Age Category'] == 'Mature']['Diagnostic Score']\n",
    "\n",
    "# Perform the Kruskal-Wallis test on the diagnostic scores\n",
    "gcse_kw_result = kruskal(gcse_young_scores, gcse_mature_scores)\n",
    "a_level_kw_result = kruskal(a_level_young_scores, a_level_mature_scores)\n",
    "\n",
    "print(\"GCSE Kruskal-Wallis Test Result:\\n\", gcse_kw_result)\n",
    "print(\"\\nA-Level Kruskal-Wallis Test Result:\\n\", a_level_kw_result)\n",
    "\n",
    "# Combine the scores and categories for Dunn's test\n",
    "gcse_scores = gcse_data[['Diagnostic Score', 'Age Category']]\n",
    "a_level_scores = a_level_data[['Diagnostic Score', 'Age Category']]\n",
    "\n",
    "# Perform Dunn's test\n",
    "gcse_dunn_result = posthoc_dunn(gcse_scores, val_col='Diagnostic Score', group_col='Age Category', p_adjust='bonferroni')\n",
    "a_level_dunn_result = posthoc_dunn(a_level_scores, val_col='Diagnostic Score', group_col='Age Category', p_adjust='bonferroni')\n",
    "\n",
    "print(\"\\nGCSE Dunn's Test Result:\\n\", gcse_dunn_result)\n",
    "print(\"\\nA-Level Dunn's Test Result:\\n\", a_level_dunn_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb25194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cacbe23",
   "metadata": {},
   "source": [
    "# Calculation of the Mean and Median for the Age Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, median, standard deviation, and count for GCSE scores\n",
    "gcse_young_mean = gcse_young_scores.mean()\n",
    "gcse_young_median = gcse_young_scores.median()\n",
    "gcse_young_std = gcse_young_scores.std()\n",
    "gcse_young_count = gcse_young_scores.count()\n",
    "\n",
    "gcse_mature_mean = gcse_mature_scores.mean()\n",
    "gcse_mature_median = gcse_mature_scores.median()\n",
    "gcse_mature_std = gcse_mature_scores.std()\n",
    "gcse_mature_count = gcse_mature_scores.count()\n",
    "\n",
    "# Calculate mean, median, standard deviation, and count for A-Level scores\n",
    "a_level_young_mean = a_level_young_scores.mean()\n",
    "a_level_young_median = a_level_young_scores.median()\n",
    "a_level_young_std = a_level_young_scores.std()\n",
    "a_level_young_count = a_level_young_scores.count()\n",
    "\n",
    "a_level_mature_mean = a_level_mature_scores.mean()\n",
    "a_level_mature_median = a_level_mature_scores.median()\n",
    "a_level_mature_std = a_level_mature_scores.std()\n",
    "a_level_mature_count = a_level_mature_scores.count()\n",
    "\n",
    "# Print the results\n",
    "print(\"GCSE Scores:\")\n",
    "print(f\"Young Students - Mean: {gcse_young_mean}, Median: {gcse_young_median}, Std Dev: {gcse_young_std}, Count: {gcse_young_count}\")\n",
    "print(f\"Mature Students - Mean: {gcse_mature_mean}, Median: {gcse_mature_median}, Std Dev: {gcse_mature_std}, Count: {gcse_mature_count}\")\n",
    "\n",
    "print(\"\\nA-Level Scores:\")\n",
    "print(f\"Young Students - Mean: {a_level_young_mean}, Median: {a_level_young_median}, Std Dev: {a_level_young_std}, Count: {a_level_young_count}\")\n",
    "print(f\"Mature Students - Mean: {a_level_mature_mean}, Median: {a_level_mature_median}, Std Dev: {a_level_mature_std}, Count: {a_level_mature_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532706b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and median for GCSE scores\n",
    "gcse_young_mean = gcse_young_scores.mean()\n",
    "gcse_young_median = gcse_young_scores.median()\n",
    "gcse_mature_mean = gcse_mature_scores.mean()\n",
    "gcse_mature_median = gcse_mature_scores.median()\n",
    "\n",
    "# Calculate mean and median for A-Level scores\n",
    "a_level_young_mean = a_level_young_scores.mean()\n",
    "a_level_young_median = a_level_young_scores.median()\n",
    "a_level_mature_mean = a_level_mature_scores.mean()\n",
    "a_level_mature_median = a_level_mature_scores.median()\n",
    "\n",
    "# Print the results\n",
    "print(\"GCSE Scores:\")\n",
    "print(f\"Young Students - Mean: {gcse_young_mean}, Median: {gcse_young_median}\")\n",
    "print(f\"Mature Students - Mean: {gcse_mature_mean}, Median: {gcse_mature_median}\")\n",
    "\n",
    "print(\"\\nA-Level Scores:\")\n",
    "print(f\"Young Students - Mean: {a_level_young_mean}, Median: {a_level_young_median}\")\n",
    "print(f\"Mature Students - Mean: {a_level_mature_mean}, Median: {a_level_mature_median}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b76198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframe\n",
    "fdata1 = pd.merge(fdata, data[['Student Number', 'PAL Attendance', 'Final Module Score']], \n",
    "                  on='Student Number', how='left')\n",
    "# Checking the result to see if it's in order\n",
    "print(fdata1.head())\n",
    "print(fdata1.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8a21f",
   "metadata": {},
   "source": [
    "# Re-attaching the PAL and Final Module Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c1f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  reattaching earlier removed features to dataframe\n",
    "fdata1 = pd.merge(fdata, data[['Student Number', 'PAL Attendance', 'Final Module Score']], \n",
    "                  on='Student Number', how='left')\n",
    "\n",
    "# Drop duplicate columns if they exist\n",
    "fdata1 = fdata1.loc[:,~fdata1.columns.duplicated()]\n",
    "\n",
    "# Checking the result\n",
    "print(fdata1.head())\n",
    "print(fdata1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b8112f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47af2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "# Filter fdata1 based on module codes to create gcse_data and a_level_data\n",
    "gcse_data = fdata1[fdata1['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata1[fdata1['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Check the first few rows of each DataFrame to confirm the separation\n",
    "print(\"GCSE Data:\")\n",
    "print(gcse_data.head())\n",
    "\n",
    "print(\"\\nA-Level Data:\")\n",
    "print(a_level_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the total number of rows in gcse_data and a_level_data\n",
    "total_gcse_data = gcse_data.shape[0]\n",
    "total_a_level_data = a_level_data.shape[0]\n",
    "\n",
    "print(f\"Total number of GCSE data: {total_gcse_data}\")\n",
    "print(f\"Total number of A-Level data: {total_a_level_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd6eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering GCSE data based on PAL attendance\n",
    "gcse_data_pal = gcse_data[gcse_data['PAL Attendance'].notna()]\n",
    "gcse_data_no_pal = gcse_data[gcse_data['PAL Attendance'].isna()]\n",
    "\n",
    "# Filtering A-Level data based on PAL attendance\n",
    "a_level_data_pal = a_level_data[a_level_data['PAL Attendance'].notna()]\n",
    "a_level_data_no_pal = a_level_data[a_level_data['PAL Attendance'].isna()]\n",
    "\n",
    "# Print the number of students in each category\n",
    "print(f\"Total number of GCSE data with PAL attendance: {gcse_data_pal.shape[0]}\")\n",
    "print(f\"Total number of GCSE data with no PAL attendance: {gcse_data_no_pal.shape[0]}\")\n",
    "print(f\"Total number of A-Level data with PAL attendance: {a_level_data_pal.shape[0]}\")\n",
    "print(f\"Total number of A-Level data with no PAL attendance: {a_level_data_no_pal.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4aa9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering GCSE data based on Final Module Score\n",
    "gcse_data_pal_final_score = gcse_data_pal[gcse_data_pal['Final Module Score'].notna()]\n",
    "gcse_data_pal_no_final_score = gcse_data_pal[gcse_data_pal['Final Module Score'].isna()]\n",
    "\n",
    "gcse_data_no_pal_final_score = gcse_data_no_pal[gcse_data_no_pal['Final Module Score'].notna()]\n",
    "gcse_data_no_pal_no_final_score = gcse_data_no_pal[gcse_data_no_pal['Final Module Score'].isna()]\n",
    "\n",
    "# Filtering A-Level data based on Final Module Score\n",
    "a_level_data_pal_final_score = a_level_data_pal[a_level_data_pal['Final Module Score'].notna()]\n",
    "a_level_data_pal_no_final_score = a_level_data_pal[a_level_data_pal['Final Module Score'].isna()]\n",
    "\n",
    "a_level_data_no_pal_final_score = a_level_data_no_pal[a_level_data_no_pal['Final Module Score'].notna()]\n",
    "a_level_data_no_pal_no_final_score = a_level_data_no_pal[a_level_data_no_pal['Final Module Score'].isna()]\n",
    "\n",
    "# Print the number of students in each category\n",
    "print(f\"Total number of GCSE data with PAL attendance and Final Module Score: {gcse_data_pal_final_score.shape[0]}\")\n",
    "print(f\"Total number of GCSE data with PAL attendance and no Final Module Score: {gcse_data_pal_no_final_score.shape[0]}\")\n",
    "print(f\"Total number of GCSE data with no PAL attendance and Final Module Score: {gcse_data_no_pal_final_score.shape[0]}\")\n",
    "print(f\"Total number of GCSE data with no PAL attendance and no Final Module Score: {gcse_data_no_pal_no_final_score.shape[0]}\")\n",
    "\n",
    "print(f\"Total number of A-Level data with PAL attendance and Final Module Score: {a_level_data_pal_final_score.shape[0]}\")\n",
    "print(f\"Total number of A-Level data with PAL attendance and no Final Module Score: {a_level_data_pal_no_final_score.shape[0]}\")\n",
    "print(f\"Total number of A-Level data with no PAL attendance and Final Module Score: {a_level_data_no_pal_final_score.shape[0]}\")\n",
    "print(f\"Total number of A-Level data with no PAL attendance and no Final Module Score: {a_level_data_no_pal_no_final_score.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f695fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53110041",
   "metadata": {},
   "source": [
    "# Imports and Initial Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Define the module codes for GCSE and A-Level modules\n",
    "gcse_modules = ['CS1MCP', 'PD1EP1', 'DT1MTP', 'CH1MAT']\n",
    "a_level_modules = ['ME1MME', 'AM10FM', 'EC1MCE', 'CE1MAT']\n",
    "\n",
    "# Drop students with final module scores less than 10\n",
    "fdata1 = fdata1[fdata1['Final Module Score'] >= 10]\n",
    "\n",
    "# Split the data into GCSE and A-Level groups\n",
    "gcse_data = fdata1[fdata1['Module Code'].isin(gcse_modules)]\n",
    "a_level_data = fdata1[fdata1['Module Code'].isin(a_level_modules)]\n",
    "\n",
    "# Filter students with no PAL attendance for each group\n",
    "gcse_data_no_pal = gcse_data[gcse_data['PAL Attendance'].isna()]\n",
    "a_level_data_no_pal = a_level_data[a_level_data['PAL Attendance'].isna()]\n",
    "\n",
    "# Filter students with PAL attendance for each group\n",
    "gcse_data_pal = gcse_data[gcse_data['PAL Attendance'].notna()]\n",
    "a_level_data_pal = a_level_data[a_level_data['PAL Attendance'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99443c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a333be70",
   "metadata": {},
   "source": [
    "# Define Functions and Train Models for No-PAL Attendance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b250e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "features = ['Age on Entry', 'Diagnostic Score', 'A-Level Score', 'Ethnicity', 'Gender', 'Highest Qualification', 'Disability?']\n",
    "target = 'Final Module Score'\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data, features, target):\n",
    "    data = data.copy()\n",
    "    data = pd.get_dummies(data, columns=['Ethnicity', 'Gender', 'Highest Qualification', 'Disability?'], drop_first=True)\n",
    "    X = data[[col for col in features if col in data.columns]]\n",
    "    y = data[target]\n",
    "    return X, y\n",
    "\n",
    "# Function to train and evaluate model\n",
    "def train_and_evaluate_model(model, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return model, r2\n",
    "\n",
    "# Models to evaluate\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest Regressor': RandomForestRegressor(random_state=42),\n",
    "    'Support Vector Regressor': SVR(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models for GCSE data with no PAL attendance\n",
    "gcse_X_no_pal, gcse_y_no_pal = preprocess_data(gcse_data_no_pal, features, target)\n",
    "gcse_results = {}\n",
    "for model_name, model in models.items():\n",
    "    _, r2 = train_and_evaluate_model(model, gcse_X_no_pal, gcse_y_no_pal)\n",
    "    gcse_results[model_name] = r2\n",
    "\n",
    "best_gcse_model_name = max(gcse_results, key=gcse_results.get)\n",
    "best_gcse_model = models[best_gcse_model_name]\n",
    "print(f\"Best GCSE Model: {best_gcse_model_name} with R^2: {gcse_results[best_gcse_model_name]}\")\n",
    "\n",
    "# Train and evaluate models for A-Level data with no PAL attendance\n",
    "a_level_X_no_pal, a_level_y_no_pal = preprocess_data(a_level_data_no_pal, features, target)\n",
    "a_level_results = {}\n",
    "for model_name, model in models.items():\n",
    "    _, r2 = train_and_evaluate_model(model, a_level_X_no_pal, a_level_y_no_pal)\n",
    "    a_level_results[model_name] = r2\n",
    "\n",
    "best_a_level_model_name = max(a_level_results, key=a_level_results.get)\n",
    "best_a_level_model = models[best_a_level_model_name]\n",
    "print(f\"Best A-Level Model: {best_a_level_model_name} with R^2: {a_level_results[best_a_level_model_name]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2da9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08da07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "054e7e3a",
   "metadata": {},
   "source": [
    "# Apply Best Model and Calculate Value Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ec8a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the best model to students with PAL attendance and calculate the value added\n",
    "def calculate_value_added(data, model, features):\n",
    "    X, y = preprocess_data(data, features, target)\n",
    "    predicted_scores = model.predict(X)\n",
    "    data['Predicted Final Module Score'] = predicted_scores\n",
    "    data['Value Added'] = data['Final Module Score'] - data['Predicted Final Module Score']\n",
    "    return data\n",
    "\n",
    "gcse_data_pal = calculate_value_added(gcse_data_pal, best_gcse_model, features)\n",
    "a_level_data_pal = calculate_value_added(a_level_data_pal, best_a_level_model, features)\n",
    "\n",
    "# Print the results\n",
    "print(gcse_data_pal[['Student Number', 'Final Module Score', 'Predicted Final Module Score', 'Value Added']])\n",
    "print(a_level_data_pal[['Student Number', 'Final Module Score', 'Predicted Final Module Score', 'Value Added']])\n",
    "\n",
    "# Summary statistics of value added\n",
    "gcse_value_added_summary = gcse_data_pal['Value Added'].describe()\n",
    "a_level_value_added_summary = a_level_data_pal['Value Added'].describe()\n",
    "\n",
    "print(\"GCSE Value Added Summary:\")\n",
    "print(gcse_value_added_summary)\n",
    "\n",
    "print(\"A-Level Value Added Summary:\")\n",
    "print(a_level_value_added_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a3f9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b69811",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Although not utilized, just examining the combined results for both GCSE and A-Level data\n",
    "gcse_tabulated = gcse_data_pal[['Student Number', 'Final Module Score', 'Predicted Final Module Score', 'Value Added']]\n",
    "gcse_tabulated['Type'] = 'GCSE'\n",
    "\n",
    "a_level_tabulated = a_level_data_pal[['Student Number', 'Final Module Score', 'Predicted Final Module Score', 'Value Added']]\n",
    "a_level_tabulated['Type'] = 'A-Level'\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "tabulated_results = pd.concat([gcse_tabulated, a_level_tabulated])\n",
    "\n",
    "# Display the tabulated results\n",
    "print(tabulated_results)\n",
    "\n",
    "# Summary statistics for GCSE and A-Level value added\n",
    "gcse_value_added_summary = gcse_data_pal['Value Added'].describe().to_frame().T\n",
    "gcse_value_added_summary['Type'] = 'GCSE'\n",
    "\n",
    "a_level_value_added_summary = a_level_data_pal['Value Added'].describe().to_frame().T\n",
    "a_level_value_added_summary['Type'] = 'A-Level'\n",
    "\n",
    "# Combine the summary statistics\n",
    "summary_statistics = pd.concat([gcse_value_added_summary, a_level_value_added_summary])\n",
    "\n",
    "# Display the summary statistics\n",
    "print(summary_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040da05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18416a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fc569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the columns to be used for model prediction\n",
    "features = ['Age on Entry', 'Diagnostic Score', 'A-Level Score', 'Ethnicity', 'Gender', 'Highest Qualification', 'Disability?']\n",
    "target = 'Final Module Score'\n",
    "\n",
    "# Ensure the feature columns are correctly processed and match the model's training features\n",
    "def preprocess_data(data, features, target):\n",
    "    data = data.copy()\n",
    "    data = pd.get_dummies(data, columns=['Ethnicity', 'Gender', 'Highest Qualification', 'Disability?'], drop_first=True)\n",
    "    # Ensure only relevant columns are selected\n",
    "    X = data[[col for col in features if col in data.columns]]\n",
    "    y = data[target]\n",
    "    return X, y\n",
    "\n",
    "# Function to calculate value added\n",
    "def calculate_value_added(data, model, features, target):\n",
    "    X, y = preprocess_data(data, features, target)\n",
    "    predicted_scores = model.predict(X)\n",
    "    data['Predicted Final Module Score'] = predicted_scores\n",
    "    data['Value Added'] = data['Final Module Score'] - data['Predicted Final Module Score']\n",
    "    return data\n",
    "\n",
    "# Filter data for GCSE and A-Level with PAL attendance\n",
    "gcse_data_pal = fdata1[(fdata1['Module Code'].isin(gcse_modules)) & (fdata1['PAL Attendance'].notna())]\n",
    "a_level_data_pal = fdata1[(fdata1['Module Code'].isin(a_level_modules)) & (fdata1['PAL Attendance'].notna())]\n",
    "\n",
    "# Calculate 'Value Added' for both datasets\n",
    "gcse_data_pal = calculate_value_added(gcse_data_pal, best_gcse_model, features, target)\n",
    "a_level_data_pal = calculate_value_added(a_level_data_pal, best_a_level_model, features, target)\n",
    "\n",
    "# Select relevant columns to display, columns that the model was trained on\n",
    "gcse_display_features = ['Student Number'] + features + ['Value Added']\n",
    "a_level_display_features = ['Student Number'] + features + ['Value Added']\n",
    "\n",
    "gcse_head = gcse_data_pal[gcse_display_features].head()\n",
    "a_level_head = a_level_data_pal[a_level_display_features].head()\n",
    "\n",
    "# Print the results\n",
    "print(\"GCSE Data - Head of Value Added with Features:\")\n",
    "print(gcse_head)\n",
    "\n",
    "print(\"\\nA-Level Data - Head of Value Added with Features:\")\n",
    "print(a_level_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df6768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f88bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the feature mappings\n",
    "disability_mapping = {\n",
    "    'No disability': 'No disability',\n",
    "    'Learning difficulty such as Dyslexia, Dyspraxia or AD(H)D': 'Neurodiversity',\n",
    "    'Two or more impairments &/or disabling medical condition': 'Other',\n",
    "    'Mental health condition challenge or disorder such as depression, schizophrenia or anxiety': 'Neurodiversity',\n",
    "    0: 'Other',\n",
    "    'Deaf or have a hearing impairment': 'Physical',\n",
    "    'Long term illness or health condition such as cancer, diabetes, chronic heart disease, HIV or epilepsy': 'Physical',\n",
    "    'Disability, impairment or medical issue not listed': 'Other',\n",
    "    'Not known': 'Other',\n",
    "    \"A social/communication impairment such as Asperger's syndrome/other autistic spectrum disorder\": 'Neurodiversity',\n",
    "    'Social or communication condition such as aspergers or autism': 'Neurodiversity',\n",
    "    'Physical impairment, mobility or dexterity issue which might require you to use crutches': 'Physical',\n",
    "    'A disability, impairment or medical condition that is not listed above': 'Other',\n",
    "    'Blind or have a visual impairment uncorrected by glasses': 'Physical'\n",
    "}\n",
    "\n",
    "qualification_mapping = {\n",
    "    'Diploma at level 3': 'L3 diploma (BTEC)',\n",
    "    'A/AS level': 'A-level',\n",
    "    'BTEC National Diploma/Certificate': 'L3 diploma (BTEC)',\n",
    "    'Level 3 quals (all are in UCAS tariff)': 'Other L3',\n",
    "    'Other qualification at level 2': 'Other',\n",
    "    'Level 3 quals (none are in UCAS Tariff)': 'Other L3',\n",
    "    'Other qualification level not known': 'Other',\n",
    "    'Level 3 quals (some are in UCAS tariff)': 'Other L3',\n",
    "    'International Baccalaureate (IB) Diploma': 'Other L3',\n",
    "    'HE access course, QAA recognised': 'Other L3',\n",
    "    'Higher Apprenticeship (level 4)': 'Other',\n",
    "    'Higher National Diploma (HND)': 'Other',\n",
    "    'Certificate of Higher Education (CertHE)': 'Other',\n",
    "    'UK first degree with honours': 'Other',\n",
    "    'Higher National Certificate (HNC)': 'Other',\n",
    "    'Other qualification at level C': 'Other',\n",
    "    'Certificate at level 3': 'L3 diploma (BTEC)',\n",
    "    'EU Level 3 eg. Maturia/Matura, Diplomasi, Abitur': 'Other L3',\n",
    "    0: 'Other',\n",
    "    'Mature stu admitted on prev exp / admissions test': 'Other',\n",
    "    'International Baccalaureate (IB) Certificate': 'A-level',\n",
    "    'Foundation degree': 'Other',\n",
    "    'Foundation course at level J': 'Other',\n",
    "    'Other qualification at level 3': 'Other L3',\n",
    "    'Not known': 'Other',\n",
    "    'Non EU Level 3 eg. High School Cert/Dip,  XII,': 'Other L3',\n",
    "    'EU (non-UK) first degree': 'Other',\n",
    "    'Diploma of Higher Education (DipHE)': 'Other',\n",
    "    'Non-EU masters degree': 'Other'\n",
    "}\n",
    "\n",
    "ethnicity_mapping = {\n",
    "    'Asian or Asian British - Bangladeshi': 'Asian Other',\n",
    "    'Asian or Asian British - Pakistani': 'Asian Pakistani',\n",
    "    'White - British': 'White',\n",
    "    'White': 'White',\n",
    "    'Black or Black British - African': 'Black',\n",
    "    'Mixed - White & Asian': 'Asian Other',\n",
    "    'Asian Other': 'Asian Other',\n",
    "    'Asian or Asian British - Indian': 'Asian Indian',\n",
    "    'Other Black Background': 'Black',\n",
    "    'Other Mixed Background': 'Other',\n",
    "    'Mixed - White & Black African': 'Black',\n",
    "    'Chinese': 'Asian Other',\n",
    "    'Other Ethnic Background': 'Other',\n",
    "    'Black or Black British - Caribbean': 'Black',\n",
    "    'Arab': 'Other',\n",
    "    'Prefer not to say': 'Other',\n",
    "    'Mixed - White & Black Caribbean': 'Black',\n",
    "    'Not Known (UCAS code)': 'Other'\n",
    "}\n",
    "\n",
    "# Apply mappings to gcse_data_pal and a_level_data_pal\n",
    "gcse_data_pal['Disability Category'] = gcse_data_pal['Disability?'].map(disability_mapping)\n",
    "gcse_data_pal['Qualification Category'] = gcse_data_pal['Highest Qualification'].map(qualification_mapping)\n",
    "gcse_data_pal['Ethnicity Category'] = gcse_data_pal['Ethnicity'].map(ethnicity_mapping)\n",
    "gcse_data_pal['Age Category'] = np.where(gcse_data_pal['Age on Entry'] >= 21, 'Mature', 'Young')\n",
    "\n",
    "a_level_data_pal['Disability Category'] = a_level_data_pal['Disability?'].map(disability_mapping)\n",
    "a_level_data_pal['Qualification Category'] = a_level_data_pal['Highest Qualification'].map(qualification_mapping)\n",
    "a_level_data_pal['Ethnicity Category'] = a_level_data_pal['Ethnicity'].map(ethnicity_mapping)\n",
    "a_level_data_pal['Age Category'] = np.where(a_level_data_pal['Age on Entry'] >= 21, 'Mature', 'Young')\n",
    "\n",
    "\n",
    "# Group and calculate average Value Added for GCSE\n",
    "gcse_grouped_by_disability = gcse_data_pal.groupby('Disability Category')['Value Added'].mean()\n",
    "gcse_grouped_by_qualification = gcse_data_pal.groupby('Qualification Category')['Value Added'].mean()\n",
    "gcse_grouped_by_ethnicity = gcse_data_pal.groupby('Ethnicity Category')['Value Added'].mean()\n",
    "gcse_grouped_by_age = gcse_data_pal.groupby('Age Category')['Value Added'].mean()\n",
    "gcse_grouped_by_gender = gcse_data_pal.groupby('Gender')['Value Added'].mean()\n",
    "\n",
    "# Group and calculate average Value Added for A-Level\n",
    "a_level_grouped_by_disability = a_level_data_pal.groupby('Disability Category')['Value Added'].mean()\n",
    "a_level_grouped_by_qualification = a_level_data_pal.groupby('Qualification Category')['Value Added'].mean()\n",
    "a_level_grouped_by_ethnicity = a_level_data_pal.groupby('Ethnicity Category')['Value Added'].mean()\n",
    "a_level_grouped_by_age = a_level_data_pal.groupby('Age Category')['Value Added'].mean()\n",
    "a_level_grouped_by_gender = a_level_data_pal.groupby('Gender')['Value Added'].mean()\n",
    "\n",
    "# Print results for GCSE\n",
    "print(\"GCSE - Average Value Added by Disability Category:\")\n",
    "print(gcse_grouped_by_disability)\n",
    "\n",
    "print(\"\\nGCSE - Average Value Added by Qualification Category:\")\n",
    "print(gcse_grouped_by_qualification)\n",
    "\n",
    "print(\"\\nGCSE - Average Value Added by Ethnicity Category:\")\n",
    "print(gcse_grouped_by_ethnicity)\n",
    "\n",
    "print(\"\\nGCSE - Average Value Added by Age Category:\")\n",
    "print(gcse_grouped_by_age)\n",
    "\n",
    "print(\"\\nGCSE - Average Value Added by Gender:\")\n",
    "print(gcse_grouped_by_gender)\n",
    "\n",
    "# Print results for A-Level\n",
    "print(\"\\nA-Level - Average Value Added by Disability Category:\")\n",
    "print(a_level_grouped_by_disability)\n",
    "\n",
    "print(\"\\nA-Level - Average Value Added by Qualification Category:\")\n",
    "print(a_level_grouped_by_qualification)\n",
    "\n",
    "print(\"\\nA-Level - Average Value Added by Ethnicity Category:\")\n",
    "print(a_level_grouped_by_ethnicity)\n",
    "\n",
    "print(\"\\nA-Level - Average Value Added by Age Category:\")\n",
    "print(a_level_grouped_by_age)\n",
    "\n",
    "print(\"\\nA-Level - Average Value Added by Gender:\")\n",
    "print(a_level_grouped_by_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009bea0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af6bc292",
   "metadata": {},
   "source": [
    "# Classification of the PAL attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc849e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the updated attendance thresholds\n",
    "def classify_pal_attendance(row, level):\n",
    "    if level == 'GCSE':\n",
    "        if 1 <= row['PAL Attendance'] <= 2:\n",
    "            return 'Low'\n",
    "        elif 3 <= row['PAL Attendance'] <= 5:\n",
    "            return 'Medium'\n",
    "        elif row['PAL Attendance'] > 5:\n",
    "            return 'High'\n",
    "    elif level == 'A-Level':\n",
    "        if 1 <= row['PAL Attendance'] <= 4:\n",
    "            return 'Low'\n",
    "        elif 5 <= row['PAL Attendance'] <= 7:\n",
    "            return 'Medium'\n",
    "        elif row['PAL Attendance'] > 7:\n",
    "            return 'High'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Apply classification to both datasets\n",
    "gcse_data_pal['PAL Attendance Category'] = gcse_data_pal.apply(classify_pal_attendance, level='GCSE', axis=1)\n",
    "a_level_data_pal['PAL Attendance Category'] = a_level_data_pal.apply(classify_pal_attendance, level='A-Level', axis=1)\n",
    "\n",
    "# Count the number of students in each category and their corresponding value added\n",
    "gcse_category_counts = gcse_data_pal.groupby('PAL Attendance Category').agg({\n",
    "    'Student Number': 'count',\n",
    "    'Value Added': 'mean'\n",
    "}).rename(columns={'Student Number': 'Count', 'Value Added': 'Average Value Added'})\n",
    "\n",
    "a_level_category_counts = a_level_data_pal.groupby('PAL Attendance Category').agg({\n",
    "    'Student Number': 'count',\n",
    "    'Value Added': 'mean'\n",
    "}).rename(columns={'Student Number': 'Count', 'Value Added': 'Average Value Added'})\n",
    "\n",
    "# Print the results\n",
    "print(\"GCSE PAL Attendance Categories and Value Added:\")\n",
    "print(gcse_category_counts)\n",
    "\n",
    "print(\"\\nA-Level PAL Attendance Categories and Value Added:\")\n",
    "print(a_level_category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dc113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd338c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81360c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c965f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ccba3e7",
   "metadata": {},
   "source": [
    "# Checking if the value added is normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50148f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Perform the Shapiro-Wilk test for normality on the \"Value Added\" for both GCSE and A-Level datasets\n",
    "gcse_value_added = gcse_data_pal['Value Added']\n",
    "a_level_value_added = a_level_data_pal['Value Added']\n",
    "\n",
    "# Shapiro-Wilk test for GCSE Value Added\n",
    "gcse_w_stat, gcse_p_value = stats.shapiro(gcse_value_added)\n",
    "print(f\"GCSE Value Added - Shapiro-Wilk Test: W-Statistic = {gcse_w_stat}, p-Value = {gcse_p_value}\")\n",
    "\n",
    "# Shapiro-Wilk test for A-Level Value Added\n",
    "a_level_w_stat, a_level_p_value = stats.shapiro(a_level_value_added)\n",
    "print(f\"A-Level Value Added - Shapiro-Wilk Test: W-Statistic = {a_level_w_stat}, p-Value = {a_level_p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bdc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe83219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bed9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0f63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc5a44e8",
   "metadata": {},
   "source": [
    "# ANOVA test for the GCSE and A_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfa5972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define the feature names\n",
    "features = ['Disability_Category', 'Qualification_Category', 'Ethnicity_Category', 'Age_Category', 'Gender']\n",
    "\n",
    "# Prepare the formula\n",
    "formula = 'Value_Added ~ ' + ' + '.join([f'C({feature})' for feature in features])\n",
    "\n",
    "# Ensure column names in your datasets are clean\n",
    "def clean_column_names(df):\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    return df\n",
    "\n",
    "# Clean column names for both datasets\n",
    "gcse_data_pal = clean_column_names(gcse_data_pal)\n",
    "a_level_data_pal = clean_column_names(a_level_data_pal)\n",
    "\n",
    "# Perform ANOVA separately for GCSE\n",
    "gcse_model = ols(formula, data=gcse_data_pal).fit()\n",
    "gcse_anova_table = sm.stats.anova_lm(gcse_model, typ=2)\n",
    "print(\"ANOVA results for GCSE:\")\n",
    "print(gcse_anova_table)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Perform ANOVA separately for A-Level\n",
    "alevel_model = ols(formula, data=a_level_data_pal).fit()\n",
    "alevel_anova_table = sm.stats.anova_lm(alevel_model, typ=2)\n",
    "print(\"ANOVA results for A-Level:\")\n",
    "print(alevel_anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d3614",
   "metadata": {},
   "source": [
    "# Tukey's test for the GCSE Qualification Category and ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0526aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Clean column names for the GCSE dataset\n",
    "gcse_data_pal = clean_column_names(gcse_data_pal)\n",
    "\n",
    "# Perform Tukey's HSD Test for Ethnicity Category\n",
    "tukey_ethnicity = pairwise_tukeyhsd(endog=gcse_data_pal['Value_Added'], groups=gcse_data_pal['Ethnicity_Category'], alpha=0.05)\n",
    "print(\"Tukey's HSD Test for Ethnicity Category:\")\n",
    "print(tukey_ethnicity)\n",
    "\n",
    "# Perform Tukey's HSD Test for Qualification Category\n",
    "tukey_qualification = pairwise_tukeyhsd(endog=gcse_data_pal['Value_Added'], groups=gcse_data_pal['Qualification_Category'], alpha=0.05)\n",
    "print(\"\\nTukey's HSD Test for Qualification Category:\")\n",
    "print(tukey_qualification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1549332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421556dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18424659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff187b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f5801c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5e408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da18c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c6550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Rename the 'Student Number' column in fdata1 to 'Student_Number'\n",
    "fdata1.rename(columns={'Student Number': 'Student_Number'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge the 'Grade' column from fdata1 into a_level_data_pal\n",
    "a_level_data_pal = a_level_data_pal.merge(\n",
    "    fdata1[['Student_Number', 'Grade']], \n",
    "    on='Student_Number', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Merge the 'Grade' column from fdata1 into gcse_data_pal\n",
    "gcse_data_pal = gcse_data_pal.merge(\n",
    "    fdata1[['Student_Number', 'Grade']], \n",
    "    on='Student_Number', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# After merging, 'Grade' should be added to both dataframes\n",
    "print(a_level_data_pal.head())\n",
    "print(gcse_data_pal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b3ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83062d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c0769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fad4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaec0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_pal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c18e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d122c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269c8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44b311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Rename 'Student Number' in fdata1 to 'Student_Number'\n",
    "fdata1.rename(columns={'Student Number': 'Student_Number'}, inplace=True)\n",
    "\n",
    "# Step 2: Merge the 'Grade' column from fdata1 into a_level_data_pal\n",
    "a_level_data_pal = a_level_data_pal.merge(\n",
    "    fdata1[['Student_Number', 'Grade']], \n",
    "    on='Student_Number', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Step 2: Merge the 'Grade' column from fdata1 into gcse_data_pal\n",
    "gcse_data_pal = gcse_data_pal.merge(\n",
    "    fdata1[['Student_Number', 'Grade']], \n",
    "    on='Student_Number', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# After merging, 'Grade' should be added to both dataframes\n",
    "print(a_level_data_pal.head())\n",
    "print(gcse_data_pal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a74a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51407ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb44369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original 'Grade_x' and rename 'Grade_y' to 'Grade'\n",
    "a_level_data_pal.drop(columns=['Grade_x'], inplace=True)\n",
    "a_level_data_pal.rename(columns={'Grade_y': 'Grade'}, inplace=True)\n",
    "\n",
    "gcse_data_pal.drop(columns=['Grade_x'], inplace=True)\n",
    "gcse_data_pal.rename(columns={'Grade_y': 'Grade'}, inplace=True)\n",
    "\n",
    "print(a_level_data_pal.head())\n",
    "print(gcse_data_pal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5bb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the columns to identify the correct one to drop\n",
    "print(a_level_data_pal.columns)\n",
    "\n",
    "# Assuming the second 'Grade' column is the duplicate one\n",
    "a_level_data_pal = a_level_data_pal.loc[:, ~a_level_data_pal.columns.duplicated()]\n",
    "gcse_data_pal = gcse_data_pal.loc[:, ~gcse_data_pal.columns.duplicated()]\n",
    "# Verify the changes\n",
    "print(a_level_data_pal.head())\n",
    "print(gcse_data_pal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f048d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493014c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NaN values are present in the Grade column\n",
    "print(a_level_data_pal['Grade'].isna().sum())\n",
    "print(gcse_data_pal['Grade'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeddfdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119038e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many NaN values are present in the Grade column\n",
    "print(a_level_data_pal['Grade'].isna().sum())\n",
    "print(gcse_data_pal['Grade'].isna().sum())\n",
    "\n",
    "#Display rows with NaN values to investigate further\n",
    "print(a_level_data_pal[a_level_data_pal['Grade'].isna()])\n",
    "print(gcse_data_pal[gcse_data_pal['Grade'].isna()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1767e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing grades in A-level data\n",
    "a_level_data_paln = a_level_data_pal.dropna(subset=['Grade'])\n",
    "\n",
    "# Remove rows with missing grades in GCSE data\n",
    "gcse_data_paln = gcse_data_pal.dropna(subset=['Grade'])\n",
    "\n",
    "# Check the shape of the new DataFrames to confirm the removal\n",
    "print(f\"a_level_data_paln shape: {a_level_data_paln.shape}\")\n",
    "print(f\"gcse_data_paln shape: {gcse_data_paln.shape}\")\n",
    "\n",
    "# confirming the first few rows to confirm\n",
    "print(a_level_data_paln.head())\n",
    "print(gcse_data_paln.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data_paln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253cd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_paln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80836b31",
   "metadata": {},
   "source": [
    "# Calculation of the new value added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228c6a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert categorical variables into dummy variables\n",
    "def prepare_data(df):\n",
    "    # Only keep the specified features\n",
    "    categorical_vars = ['Gender', 'Ethnicity', 'Highest_Qualification', 'Disability_Category', 'Age_Category']\n",
    "    df_dummies = pd.get_dummies(df[categorical_vars], drop_first=True)\n",
    "    \n",
    "    return df_dummies\n",
    "# We assume 'Final_Module_Score' >= 60 is considered a 'good degree'\n",
    "a_level_data_paln['Good_Degree'] = np.where(a_level_data_paln['Final_Module_Score'] >= 60, 1, 0)\n",
    "gcse_data_paln['Good_Degree'] = np.where(gcse_data_paln['Final_Module_Score'] >= 60, 1, 0)\n",
    "\n",
    "# Prepare the features and target variable\n",
    "X_a_level = prepare_data(a_level_data_paln)\n",
    "y_a_level = a_level_data_paln['Good_Degree']\n",
    "\n",
    "X_gcse = prepare_data(gcse_data_paln)\n",
    "y_gcse = gcse_data_paln['Good_Degree']\n",
    "\n",
    "#Train the logistic regression model\n",
    "log_reg_a_level = LogisticRegression(max_iter=1000)\n",
    "log_reg_gcse = LogisticRegression(max_iter=1000)\n",
    "\n",
    "log_reg_a_level.fit(X_a_level, y_a_level)\n",
    "log_reg_gcse.fit(X_gcse, y_gcse)\n",
    "\n",
    "#Predict the probabilities\n",
    "a_level_data_paln['Probability'] = log_reg_a_level.predict_proba(X_a_level)[:, 1]\n",
    "gcse_data_paln['Probability'] = log_reg_gcse.predict_proba(X_gcse)[:, 1]\n",
    "\n",
    "#Calculate the value-added score\n",
    "a_level_data_paln['Value_Added_New'] = np.where(a_level_data_paln['Good_Degree'] == 1, 1 / a_level_data_paln['Probability'], 0)\n",
    "gcse_data_paln['Value_Added_New'] = np.where(gcse_data_paln['Good_Degree'] == 1, 1 / gcse_data_paln['Probability'], 0)\n",
    "\n",
    "#Inspect the new value-added scores\n",
    "print(a_level_data_paln[['Student_Number', 'Grade', 'Probability', 'Value_Added_New']].head())\n",
    "print(gcse_data_paln[['Student_Number', 'Grade', 'Probability', 'Value_Added_New']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b665c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdb83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcse_data_paln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8ce1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_data_paln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584a159",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk normality test for the new value added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535331ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Shapiro-Wilk Test for normality on A-level data\n",
    "shapiro_test_a_level = shapiro(a_level_data_paln['Value_Added_New'])\n",
    "print(f\"A-Level Value Added Normality Test: W-statistic = {shapiro_test_a_level.statistic}, p-value = {shapiro_test_a_level.pvalue}\")\n",
    "\n",
    "# Shapiro-Wilk Test for normality on GCSE data\n",
    "shapiro_test_gcse = shapiro(gcse_data_paln['Value_Added_New'])\n",
    "print(f\"GCSE Value Added Normality Test: W-statistic = {shapiro_test_gcse.statistic}, p-value = {shapiro_test_gcse.pvalue}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b58280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Features to test\n",
    "features = ['Gender', 'Ethnicity', 'Highest_Qualification', 'Disability_Category', 'Age_Category']\n",
    "\n",
    "# Function to perform Kruskal-Wallis H test\n",
    "def kruskal_wallis_test(df, features, value_added_column):\n",
    "    results = {}\n",
    "    for feature in features:\n",
    "        # Group by the feature and extract the Value_Added_New column\n",
    "        groups = [group[value_added_column].dropna() for name, group in df.groupby(feature)]\n",
    "        if len(groups) > 1:  # Ensure there are at least two groups to compare\n",
    "            stat, p = kruskal(*groups)\n",
    "            results[feature] = {'Kruskal-Wallis H statistic': stat, 'p-value': p}\n",
    "    return results\n",
    "\n",
    "# Perform the test for a_level_data_paln\n",
    "a_level_results = kruskal_wallis_test(a_level_data_paln, features, 'Value_Added_New')\n",
    "print(\"A-Level Data Kruskal-Wallis Test Results:\")\n",
    "for feature, result in a_level_results.items():\n",
    "    print(f\"{feature}: H-statistic = {result['Kruskal-Wallis H statistic']}, p-value = {result['p-value']}\")\n",
    "\n",
    "# Perform the test for gcse_data_paln\n",
    "gcse_results = kruskal_wallis_test(gcse_data_paln, features, 'Value_Added_New')\n",
    "print(\"\\nGCSE Data Kruskal-Wallis Test Results:\")\n",
    "for feature, result in gcse_results.items():\n",
    "    print(f\"{feature}: H-statistic = {result['Kruskal-Wallis H statistic']}, p-value = {result['p-value']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d1d5f",
   "metadata": {},
   "source": [
    "# Checking the relationship between the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890c63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate correlation for A-Level data\n",
    "correlation_a_level = a_level_data_paln['Value_Added'].corr(a_level_data_paln['Value_Added_New'])\n",
    "print(f\"A-Level Data Correlation between Value_Added and Value_Added_New: {correlation_a_level}\")\n",
    "\n",
    "# Calculate correlation for GCSE data\n",
    "correlation_gcse = gcse_data_paln['Value_Added'].corr(gcse_data_paln['Value_Added_New'])\n",
    "print(f\"GCSE Data Correlation between Value_Added and Value_Added_New: {correlation_gcse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c470b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47ee518a",
   "metadata": {},
   "source": [
    "# Scaling the data and still checking the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3888dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Function to normalize the value added columns\n",
    "def normalize_value_added_columns(df, columns):\n",
    "    df_normalized = df.copy()\n",
    "    df_normalized[columns] = scaler.fit_transform(df[columns])\n",
    "    return df_normalized\n",
    "\n",
    "# Normalize the value added columns for A-Level data\n",
    "a_level_normalized = normalize_value_added_columns(a_level_data_paln, ['Value_Added', 'Value_Added_New'])\n",
    "\n",
    "# Normalize the value added columns for GCSE data\n",
    "gcse_normalized = normalize_value_added_columns(gcse_data_paln, ['Value_Added', 'Value_Added_New'])\n",
    "\n",
    "# Calculate correlation for normalized A-Level data\n",
    "correlation_a_level_normalized = a_level_normalized['Value_Added'].corr(a_level_normalized['Value_Added_New'])\n",
    "print(f\"A-Level Data Correlation between Normalized Value_Added and Value_Added_New: {correlation_a_level_normalized}\")\n",
    "\n",
    "# Calculate correlation for normalized GCSE data\n",
    "correlation_gcse_normalized = gcse_normalized['Value_Added'].corr(gcse_normalized['Value_Added_New'])\n",
    "print(f\"GCSE Data Correlation between Normalized Value_Added and Value_Added_New: {correlation_gcse_normalized}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15174d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_level_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69a4e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78b9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9632f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4131e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e32672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
